# -*- coding: utf-8 -*-
"""pores_vgg16_pores_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16RZrrIvu4qS0aJC6gPkbqNt0mxCBYbnE
"""

pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 --index-url https://download.pytorch.org/whl/cu121
pip install scikit-learn
pip install matplotlib
pip install opencv-python

categories = ['pores', 'non_pores']

import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"Current device: {torch.cuda.get_device_name(0)}" if torch.cuda.is_available() else "CPU is being used")
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, WeightedRandomSampler
import torchvision.transforms as transforms
from torchvision import models
from sklearn.model_selection import train_test_split
from PIL import Image
import matplotlib.pyplot as plt
import os
import numpy as np
from collections import Counter
# from google.colab import files
import cv2

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class EarlyStopping:
    def __init__(self, patience=5, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

def load_data():
    all_data = []
    all_labels = []
    for idx, category in enumerate(categories):
        category_dir = os.path.join(data_dir, category)
        for file_name in os.listdir(category_dir):
            if file_name.endswith(('.jpg', '.jpeg', '.png')):
                all_data.append(os.path.join(category_dir, file_name))
                all_labels.append(label_dict[category])
    return all_data, all_labels

class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform

    # Contrast enhancement method
    def enhance_contrast(self, image):
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        cl = clahe.apply(l)
        enhanced = cv2.merge((cl, a, b))
        return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # Load the image
        image_path = self.data[idx]
        with Image.open(image_path) as img:
            image = img.convert('RGB')

        # Convert PIL image to NumPy array for OpenCV
        image = np.array(image)

        # Apply contrast enhancement
        image = self.enhance_contrast(image)

        # Convert NumPy array back to PIL image for transforms
        image = Image.fromarray(image)

        # Apply other transformations
        if self.transform:
            image = self.transform(image)

        # Get the label
        label = self.labels[idx]
        return image, label

def create_weighted_sampler(labels):
    class_counts = Counter(labels)
    total_samples = len(labels)
    class_weights = {class_idx: total_samples / count for class_idx, count in class_counts.items()}
    weights = [class_weights[label] for label in labels]
    weights = torch.DoubleTensor(weights)
    sampler = WeightedRandomSampler(weights, len(weights))
    return sampler

# Replace AlexNet with VGG16
class VGG16Model(nn.Module):
    def __init__(self, num_classes):
        super(VGG16Model, self).__init__()
        self.backbone = models.vgg16(pretrained=True)
        for param in self.backbone.features.parameters():
            param.requires_grad = False

        for param in self.backbone.features[-4:].parameters():
            param.requires_grad = True

        self.backbone.classifier = nn.Sequential(
            nn.Linear(25088, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5),
            nn.Linear(4096, 2048),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.4),
            nn.Linear(2048, num_classes)
        )

        for m in self.backbone.classifier.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        return self.backbone(x)

# Training loop
def train(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs):
    train_losses = []
    valid_losses = []
    train_accuracies = []
    valid_accuracies = []
    best_model_wts = model.state_dict()
    best_acc = 0.0

    early_stopping = EarlyStopping(patience=5)

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        train_loss = running_loss / len(train_loader.dataset)
        train_acc = 100 * correct / total
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)

        model.eval()
        running_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                running_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        val_loss = running_loss / len(val_loader.dataset)
        val_acc = 100 * correct / total
        valid_losses.append(val_loss)
        valid_accuracies.append(val_acc)

        scheduler.step(val_loss)

        print(f"Epoch [{epoch+1}/{num_epochs}], "
              f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, "
              f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")


        early_stopping(val_loss)
        if early_stopping.early_stop:
            print("Early stopping triggered")
            break


        if val_acc > best_acc:
            best_acc = val_acc
            best_model_wts = model.state_dict()

    model.load_state_dict(best_model_wts)
    return train_losses, valid_losses, train_accuracies, valid_accuracies

def predict_image(model, image_path, transform, categories, temperature=2.5):  # temperature 값 조정 가능
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0)
    image = image.to(device)

    model.eval()
    with torch.no_grad():
        output = model(image)

        # Temperature scaling 적용
        scaled_logits = output / temperature
        probabilities = torch.nn.functional.softmax(scaled_logits, dim=1)[0]

        # 각 클래스의 확률을 계산
        flushing_prob = float(probabilities[0] * 100)
        normal_prob = float(probabilities[1] * 100)

        # 결과 출력
        print("\n피부 모공 분석 결과:")
        if flushing_prob > normal_prob:
            print("모공이 있습니다.")
        else:
            print("모공이 없습니다.")
        print(f"확률: 모공 {flushing_prob:.1f}% / 정상 {normal_prob:.1f}%")

    return {"flushing": flushing_prob, "normal": normal_prob}

def plot_metrics(train_losses, valid_losses, train_accuracies, valid_accuracies):
    epochs = range(1, len(train_losses) + 1)

    plt.figure(figsize=(15, 5))

    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, 'b-', label='Training Loss')
    plt.plot(epochs, valid_losses, 'r-', label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')
    plt.plot(epochs, valid_accuracies, 'r-', label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Data directory and categories
data_dir = "/경로"

# '/content/drive/MyDrive/Colab Notebooks/skin_type/classification/pores_dataset'

categories = ['pores', 'non_pores']
label_dict = {'pores': 0, 'non_pores': 1}

# Hyperparameters
hyperparameters = {
    'batch_size': 64,
    'learning_rate': 0.001,
    'num_epochs': 100,
    'dropout_rate': 0.3,
    'weight_decay': 5e-4,
}

from torchvision.transforms import RandomErasing
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),                       # 크기 조정
    transforms.RandomHorizontalFlip(p=0.7),             # 가로 방향 뒤집기 확률 증가
    transforms.RandomVerticalFlip(p=0.3),               # 세로 방향 뒤집기 확률 증가
    transforms.RandomRotation(degrees=45),              # 회전 각도 증가 (30 → 45)
    transforms.ColorJitter(brightness=0.4,              # 밝기 조정 강화
                           contrast=0.4,
                           saturation=0.4,
                           hue=0.2),                    # 색조 조정 강화
    transforms.RandomAffine(degrees=0,
                            shear=20,                   # 전단 강도 증가
                            scale=(0.5, 1.5),           # 확대/축소 범위 확장
                            translate=(0.2, 0.2)),      # 이동 허용 범위 추가
    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),  # 가우시안 블러 추가
    transforms.RandomGrayscale(p=0.2),                 # 흑백 변환 확률 추가
    transforms.ToTensor(),                              # 텐서로 변환
    transforms.Normalize(mean=[0.485, 0.456, 0.406],    # 정규화
                         std=[0.229, 0.224, 0.225]),
    RandomErasing(p=0.7, scale=(0.02, 0.2), ratio=(0.3, 3.3))  # 랜덤 영역 삭제 강화
])

transform_valid = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

all_data, all_labels = load_data()

# Train-test split
train_data, valid_data, train_labels, valid_labels = train_test_split(
    all_data, all_labels, test_size=0.2, stratify=all_labels, random_state=42
)

train_dataset = CustomDataset(train_data, train_labels, transform=transform_train)
valid_dataset = CustomDataset(valid_data, valid_labels, transform=transform_valid)

train_sampler = create_weighted_sampler(train_labels)
train_loader = DataLoader(
    train_dataset,
    batch_size=hyperparameters['batch_size'],
    sampler=train_sampler,
    num_workers=4,
    pin_memory=True
)

valid_loader = DataLoader(
    valid_dataset,
    batch_size=hyperparameters['batch_size'],
    shuffle=False,
    num_workers=4,
    pin_memory=True
)

model = VGG16Model(num_classes=len(categories)).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(
    model.parameters(),
    lr=hyperparameters['learning_rate'],
    weight_decay=hyperparameters['weight_decay'],
    amsgrad=True
)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.1,
    patience=3,
    verbose=True
)

import torch
torch.cuda.get_device_name(0)

import torch
torch.cuda.empty_cache()

import os

# 테스트할 이미지 경로
test_image_path = '/경로'

# 경로 확인 함수
def check_path(path):
    if os.path.exists(path):  # 경로가 존재하는지 확인
        if os.path.isfile(path):  # 경로가 파일인지 확인
            print(f"경로가 존재하며, 파일이 확인되었습니다: {path}")
        else:
            print(f"경로는 존재하지만, 파일이 아닙니다: {path}")
    else:
        print(f"경로가 존재하지 않습니다: {path}")

# 경로 확인 실행
check_path(test_image_path)

print('시작')

train_losses, valid_losses, train_accuracies, valid_accuracies = train(
    model, criterion, optimizer, scheduler, train_loader, valid_loader,
    hyperparameters['num_epochs']
)

# torch.save(model.state_dict(), 'best_vgg18_model_pores.pth')
# # files.download('best_vgg18_model_pores.pth')

# 모델 저장 경로 설정
model_save_path = "/home/elicer/best_vgg18_model_pores.pth"  # 현재 디렉토리에 저장

# 모델 저장
torch.save(model.state_dict(), model_save_path)
print(f"Model saved at: {model_save_path}")


model = VGG16Model(num_classes=len(categories)).to(device)


model.load_state_dict(torch.load('best_vgg18_model_pores.pth'))
model.eval()


plot_metrics(train_losses, valid_losses, train_accuracies, valid_accuracies)

test_image_path = '/경로'
predict_image(model, test_image_path, transform_valid, categories)

from PIL import Image
import matplotlib.pyplot as plt

# 이미지를 열고 표시
img = Image.open(test_image_path)
plt.imshow(img)
plt.title("Input Image")
plt.axis('off')
plt.show()

import cv2
print(f"OpenCV version: {cv2.__version__}")

torch.backends.cudnn.benchmark=False
torch.backends.cudnn.deterministic=True

# 모델 저장 경로 설정
model_save_path = "/경로/best_vgg18_model_pores_dataset_changed_ver.pth"  # 현재 디렉토리에 저장
model = VGG16Model(num_classes=len(categories)).to(device)

model.load_state_dict(torch.load(model_save_path))
model.eval()

test_image_path = '/경로'
predict_image(model, test_image_path, transform_valid, categories)

from PIL import Image
import matplotlib.pyplot as plt

# 이미지를 열고 표시
img = Image.open(test_image_path)
plt.imshow(img)
plt.title("Input Image")
plt.axis('off')
plt.show()